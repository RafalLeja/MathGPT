{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(3407)\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 1, 2, 3, 11, 13, 10, 4, 5, 6, 11, 12, 10, 6, 11, 14, 17]\n",
      "123+456*6=\n"
     ]
    }
   ],
   "source": [
    "StT = {\n",
    "    \"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9,\n",
    "    \"NumBeg\": 10, \"NumEnd\": 11, \"*\": 12, \"+\": 13, \"=\": 14, \"ThinkBeg\": 15, \"ThinkEnd\": 16, \"Eos\": 17\n",
    "}\n",
    "\n",
    "TtS = {v: k for k, v in StT.items()}\n",
    "\n",
    "def tokenize(s):\n",
    "    out = []\n",
    "    num = False\n",
    "    past = \"\"\n",
    "    for c in s:\n",
    "        chars = past + c\n",
    "        if chars in StT:\n",
    "            tok = StT[chars]\n",
    "            if tok < 10:\n",
    "                if not num:\n",
    "                    out.append(StT[\"NumBeg\"])\n",
    "                    num = True\n",
    "                out.append(tok)\n",
    "            else:\n",
    "                if num:\n",
    "                    out.append(StT[\"NumEnd\"])\n",
    "                    num = False\n",
    "                out.append(tok)\n",
    "            past = \"\"\n",
    "        else:\n",
    "            past += c\n",
    "\n",
    "    return out + [StT[\"Eos\"]]\n",
    "\n",
    "def detokenize(toks):\n",
    "    out = []\n",
    "    num = False\n",
    "    for tok in toks:\n",
    "        if tok == 17:\n",
    "            break\n",
    "        \n",
    "        if tok == 10 or tok == 11 or (tok >= 15 and tok <= 17) :\n",
    "            continue\n",
    "        out.append(TtS[tok])\n",
    "\n",
    "    return \"\".join(out)\n",
    "\n",
    "example = \"123+456*6=\"\n",
    "print(tokenize(example))\n",
    "print(detokenize(tokenize(example)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536*62=ThinkBeg500*62+30*62+6*62=31000+1860+372=ThinkEnd33232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def step_mul(length):\n",
    "    a = [random.randint(0,9) for i in range(length)]\n",
    "    b = [random.randint(0,9) for i in range(length)]\n",
    "    # a = [9, 9, 9]\n",
    "    # b = [9, 9, 9]\n",
    "\n",
    "    val_a = int(''.join(str(d) for d in a))\n",
    "    val_b = int(''.join(str(d) for d in b))\n",
    "    if val_a < val_b:\n",
    "        val_a, val_b = val_b, val_a\n",
    "        a, b = b, a\n",
    "    \n",
    "    string = f\"{val_a}*{val_b}=ThinkBeg\"\n",
    "\n",
    "    steps_eq = []\n",
    "    for i in range(length):\n",
    "        a_i = a[i] * 10**(length-i-1)\n",
    "        # a_i = str(a[i]) \n",
    "        string += f\"{a_i}*{val_b}+\"\n",
    "        steps_eq.append(str(a_i*val_b)+\"+\")\n",
    "\n",
    "    string = string[:-1] + \"=\" + \"\".join(steps_eq)[:-1] + \"=\" + \"ThinkEnd\" + str(val_a*val_b)\n",
    "\n",
    "    return string\n",
    "    # print(out)\n",
    "\n",
    "eq = step_mul(3)\n",
    "print(eq)\n",
    "tokenize(eq)\n",
    "len(tokenize(eq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Add problem. E.g. for problem length 3:\n",
    "    12 + 333 = 345\n",
    "    Input: 0 1 2 3 3 3 -> Output: 0 3 4 5\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:  0 1 2 3 3 3 0 3 4\n",
    "    output: I I I I I 0 3 4 5\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 100000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return len(StT)\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return 79\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            rai = tokenize(step_mul(self.length))\n",
    "            h = hash(str(rai[:1+2*(self.length+2)]))\n",
    "            \n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        if len(rai) < self.get_block_size():\n",
    "            rai += [StT[\"Eos\"]] * (self.get_block_size() - len(rai))\n",
    "        \n",
    "        x = torch.tensor(rai[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(rai[1:], dtype=torch.long)\n",
    "        \n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        y[:2*(self.length+2)+1] = -1\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  4,  9,  5, 11, 12, 10,  3,  7,  8, 11, 14, 15, 10,  4,  0,  0, 11,\n",
      "        12, 10,  3,  7,  8, 11, 13, 10,  9,  0, 11, 12, 10,  3,  7,  8, 11, 13,\n",
      "        10,  5, 11, 12, 10,  3,  7,  8, 11, 14, 10,  1,  5,  1,  2,  0,  0, 11,\n",
      "        13, 10,  3,  4,  0,  2,  0, 11, 13, 10,  1,  8,  9,  0, 11, 14, 16, 10,\n",
      "         1,  8,  7,  1,  1,  0])\n",
      "10 -1\n",
      "4 -1\n",
      "9 -1\n",
      "5 -1\n",
      "11 -1\n",
      "12 -1\n",
      "10 -1\n",
      "3 -1\n",
      "7 -1\n",
      "8 -1\n",
      "11 -1\n",
      "14 15\n",
      "15 10\n",
      "10 4\n",
      "4 0\n",
      "0 0\n",
      "0 11\n",
      "11 12\n",
      "12 10\n",
      "10 3\n",
      "3 7\n",
      "7 8\n",
      "8 11\n",
      "11 13\n",
      "13 10\n",
      "10 9\n",
      "9 0\n",
      "0 11\n",
      "11 12\n",
      "12 10\n",
      "10 3\n",
      "3 7\n",
      "7 8\n",
      "8 11\n",
      "11 13\n",
      "13 10\n",
      "10 5\n",
      "5 11\n",
      "11 12\n",
      "12 10\n",
      "10 3\n",
      "3 7\n",
      "7 8\n",
      "8 11\n",
      "11 14\n",
      "14 10\n",
      "10 1\n",
      "1 5\n",
      "5 1\n",
      "1 2\n",
      "2 0\n",
      "0 0\n",
      "0 11\n",
      "11 13\n",
      "13 10\n",
      "10 3\n",
      "3 4\n",
      "4 0\n",
      "0 2\n",
      "2 0\n",
      "0 11\n",
      "11 13\n",
      "13 10\n",
      "10 1\n",
      "1 8\n",
      "8 9\n",
      "9 0\n",
      "0 11\n",
      "11 14\n",
      "14 16\n",
      "16 10\n",
      "10 1\n",
      "1 8\n",
      "8 7\n",
      "7 1\n",
      "1 1\n",
      "1 0\n",
      "0 17\n"
     ]
    }
   ],
   "source": [
    "# print an example instance of the dataset\n",
    "train_dataset = MulDataset('train')\n",
    "test_dataset = MulDataset('test')\n",
    "x, y = train_dataset[0]\n",
    "\n",
    "print (x)\n",
    "for a, b in zip(x,y):\n",
    "    print(int(a),int(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type: None\n",
      "n_layer: 12\n",
      "n_head: 8\n",
      "n_embd: 256\n",
      "vocab_size: None\n",
      "block_size: None\n",
      "embd_pdrop: 0.1\n",
      "resid_pdrop: 0.1\n",
      "attn_pdrop: 0.1\n",
      "\n",
      "number of parameters: 9.50M\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT\n",
    "\n",
    "HEADS = 8\n",
    "LAYERS = 12\n",
    "EMBEDDING_DIM = 256\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = None\n",
    "# model_config.model_type = 'gpt-nano'\n",
    "model_config.n_head = HEADS\n",
    "model_config.n_layer = LAYERS\n",
    "model_config.n_embd = EMBEDDING_DIM\n",
    "print (model_config)\n",
    "\n",
    "model_config.vocab_size = train_dataset.get_vocab_size()\n",
    "model_config.block_size = train_dataset.get_block_size()\n",
    "model = GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make sure the model directory exists\n",
    "if not os.path.exists(f'../weights/elasitc/el_mul_{HEADS}_{LAYERS}'):\n",
    "    os.makedirs(f'../weights/elasitc/el_mul_{HEADS}_{LAYERS}')\n",
    "    model.load_state_dict(torch.load(f'../weights/elastic/el_mul_{HEADS}_{LAYERS}/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 12 256\n"
     ]
    }
   ],
   "source": [
    "print (model_config.n_head, model_config.n_layer, model_config.n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 1e-6 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 5000\n",
    "train_config.num_workers = 0\n",
    "# train_config.batch_size = 32\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 0.04060\n",
      "iter_dt 435.05ms; iter 100: train loss 0.02424\n",
      "iter_dt 430.29ms; iter 200: train loss 0.02249\n",
      "iter_dt 437.78ms; iter 300: train loss 0.02493\n",
      "iter_dt 435.56ms; iter 400: train loss 0.02429\n",
      "iter_dt 430.29ms; iter 500: train loss 0.02646\n",
      "iter_dt 436.54ms; iter 600: train loss 0.02481\n",
      "iter_dt 437.03ms; iter 700: train loss 0.02286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter_dt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39miter_dt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mms; iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39miter_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mset_callback(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_batch_end\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_end_callback)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/minGPT/mingpt/trainer.py:89\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m     data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m     88\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[0;32m---> 89\u001b[0m batch \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     90\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# forward the model\u001b[39;00m\n",
      "File \u001b[0;32m~/minGPT/mingpt/trainer.py:89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     87\u001b[0m     data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m     88\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[0;32m---> 89\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     90\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# forward the model\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's perform some evaluation\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  6,  2,  4, 11, 12, 10,  5,  3,  4, 11, 14])\n",
      "tensor([10,  3,  3,  3,  2,  1,  6, 17])\n",
      "10 10\n",
      "6 3\n",
      "2 3\n",
      "4 3\n",
      "11 2\n",
      "12 1\n",
      "10 6\n",
      "5 17\n"
     ]
    }
   ],
   "source": [
    "class EvalMulDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Add problem. E.g. for problem length 3:\n",
    "    12 + 333 = 345\n",
    "    Input: 0 1 2 3 3 3 -> Output: 0 3 4 5\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:  0 1 2 3 3 3 0 3 4\n",
    "    output: I I I I I 0 3 4 5\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 100000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return len(StT)\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return 79\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            rai = tokenize(step_mul(self.length))\n",
    "            h = hash(str(rai[:1+2*(self.length+2)]))\n",
    "            \n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        x = torch.tensor(rai[:-1], dtype=torch.long)[:rai.index(StT[\"=\"])+1]\n",
    "        y = torch.tensor(rai[1:], dtype=torch.long)[rai.index(StT[\"ThinkEnd\"]):]\n",
    "        \n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        return x, y\n",
    "    \n",
    "eval_train_dataset = EvalMulDataset('train')\n",
    "eval_test_dataset = EvalMulDataset('test')\n",
    "x, y = eval_train_dataset[0]\n",
    "\n",
    "print (x)\n",
    "print (y)\n",
    "for a, b in zip(x,y):\n",
    "    print(int(a),int(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10,  9,  7,  2, 11, 12, 10,  2,  2,  0, 11, 14, 15, 10,  9,  0,  0, 11,\n",
      "         12, 10,  2,  2,  0, 11, 13, 10,  7,  0, 11, 12, 10,  2,  2,  0, 11, 13,\n",
      "         10,  2, 11, 12, 10,  2,  2,  0, 11, 14, 10,  1,  9,  8,  0,  0,  0, 11,\n",
      "         13, 10,  1,  5,  4,  0,  0, 11, 13, 10,  4,  4,  0, 11, 14, 16, 10,  2,\n",
      "          1,  3,  8,  4,  0, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 12, 10,  0]], device='cuda:0')\n",
      "972*220=\n",
      "972*220=900*220+70*220+2*220=198000+15400+440=213840\n",
      "Accuracy: 6/10 = 0.60\n",
      "Accuracy: 11/20 = 0.55\n",
      "Accuracy: 17/30 = 0.57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(detokenize(input_tensor[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(detokenize(out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[0;32m---> 41\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_test_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[66], line 16\u001b[0m, in \u001b[0;36mevaluate_model_accuracy\u001b[0;34m(model, eval_dataset, n)\u001b[0m\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m79\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(detokenize(x[0].cpu().numpy()))\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(detokenize(y[0].cpu().numpy()))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detokenize(y[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/minGPT/mingpt/model.py:293\u001b[0m, in \u001b[0;36mGPT.generate\u001b[0;34m(self, idx, max_new_tokens, temperature, do_sample, top_k)\u001b[0m\n\u001b[1;32m    291\u001b[0m idx_cond \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;28;01mif\u001b[39;00m idx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size \u001b[38;5;28;01melse\u001b[39;00m idx[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size:]\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# forward the model to get the logits for the index in the sequence\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m logits, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# pluck the logits at the final step and scale by desired temperature\u001b[39;00m\n\u001b[1;32m    295\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m/\u001b[39m temperature\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/minGPT/mingpt/model.py:271\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mdrop(tok_emb \u001b[38;5;241m+\u001b[39m pos_emb)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh:\n\u001b[0;32m--> 271\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mln_f(x)\n\u001b[1;32m    273\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/minGPT/mingpt/model.py:92\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     91\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x))\n\u001b[0;32m---> 92\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlpf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/minGPT/mingpt/model.py:88\u001b[0m, in \u001b[0;36mBlock.__init__.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleDict(\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     82\u001b[0m     c_fc    \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mn_embd, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mn_embd),\n\u001b[1;32m     83\u001b[0m     c_proj  \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mn_embd, config\u001b[38;5;241m.\u001b[39mn_embd),\n\u001b[1;32m     84\u001b[0m     act     \u001b[38;5;241m=\u001b[39m NewGELU(),\n\u001b[1;32m     85\u001b[0m     dropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mresid_pdrop),\n\u001b[1;32m     86\u001b[0m ))\n\u001b[1;32m     87\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlpf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: m\u001b[38;5;241m.\u001b[39mdropout(m\u001b[38;5;241m.\u001b[39mc_proj(m\u001b[38;5;241m.\u001b[39mact(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate_model_accuracy(model, eval_dataset, n = 100):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(eval_dataset)):\n",
    "            x, y = eval_dataset[i]\n",
    "            x = x.unsqueeze(0).to(device)\n",
    "            y = y.unsqueeze(0).to(device)\n",
    "\n",
    "            output = model.generate(x, 79, do_sample=False)\n",
    "            # print(detokenize(x[0].cpu().numpy()))\n",
    "            # print(detokenize(y[0].cpu().numpy()))\n",
    "            y = int(detokenize(y[0].cpu().numpy()))\n",
    "            predicted = int(detokenize(output[0].cpu().numpy()).split(\"=\")[-1])\n",
    "            # print(predicted)\n",
    "\n",
    "            # Compare predicted and actual values\n",
    "            correct += 1 if y == predicted else 0\n",
    "            total += 1\n",
    "\n",
    "            if total % 10 == 0:\n",
    "                print(f\"Accuracy: {correct}/{total} = {correct/total:.2f}\")\n",
    "\n",
    "            if total >= n:\n",
    "                break\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "input_tensor = eval_test_dataset[0][0].unsqueeze(0).to(device)\n",
    "out = model.generate(input_tensor, 120, do_sample=False)\n",
    "print(out)\n",
    "print(detokenize(input_tensor[0].cpu().numpy()))\n",
    "print(detokenize(out[0].cpu().numpy()))\n",
    "accuracy = evaluate_model_accuracy(model, eval_test_dataset)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../weights/elastic/el_mul_{HEADS}_{LAYERS}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 4.76M\n",
      "running on device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69237/3834584001.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'../weights/elastic/el_mul_{heads}_{layers}.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4/10 = 0.40\n",
      "Accuracy: 5/20 = 0.25\n",
      "Accuracy: 11/30 = 0.37\n",
      "Accuracy: 14/40 = 0.35\n",
      "Accuracy: 18/50 = 0.36\n",
      "Accuracy: 21/60 = 0.35\n",
      "Accuracy: 23/70 = 0.33\n",
      "Accuracy: 29/80 = 0.36\n",
      "Accuracy: 33/90 = 0.37\n",
      "Accuracy: 38/100 = 0.38\n",
      "number of parameters: 6.34M\n",
      "running on device cuda\n",
      "Accuracy: 6/10 = 0.60\n",
      "Accuracy: 15/20 = 0.75\n",
      "Accuracy: 20/30 = 0.67\n",
      "Accuracy: 25/40 = 0.62\n",
      "Accuracy: 30/50 = 0.60\n",
      "Accuracy: 33/60 = 0.55\n",
      "Accuracy: 39/70 = 0.56\n",
      "Accuracy: 43/80 = 0.54\n",
      "Accuracy: 48/90 = 0.53\n",
      "Accuracy: 54/100 = 0.54\n",
      "number of parameters: 9.50M\n",
      "running on device cuda\n",
      "Accuracy: 5/10 = 0.50\n",
      "Accuracy: 13/20 = 0.65\n",
      "Accuracy: 22/30 = 0.73\n",
      "Accuracy: 29/40 = 0.72\n",
      "Accuracy: 35/50 = 0.70\n",
      "Accuracy: 42/60 = 0.70\n",
      "Accuracy: 50/70 = 0.71\n",
      "Accuracy: 56/80 = 0.70\n",
      "Accuracy: 64/90 = 0.71\n",
      "Accuracy: 71/100 = 0.71\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "\n",
    "heads_unique = [8]\n",
    "layers_unique = [6, 8, 12]\n",
    "\n",
    "for heads in heads_unique:\n",
    "    h_s = []\n",
    "    for layers in layers_unique:\n",
    "        model_config = GPT.get_default_config()\n",
    "        model_config.model_type = None\n",
    "        model_config.n_head = heads\n",
    "        model_config.n_layer = layers\n",
    "        model_config.n_embd = 256\n",
    "        model_config.vocab_size = train_dataset.get_vocab_size()\n",
    "        model_config.block_size = train_dataset.get_block_size()\n",
    "        # print (model_config)\n",
    "        model = GPT(model_config)\n",
    "\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.load_state_dict(torch.load(f'../weights/elastic/el_mul_{heads}_{layers}.pth', map_location=device))\n",
    "\n",
    "        train_config = Trainer.get_default_config()\n",
    "        train_config.learning_rate = 1e-4 # the model we're using is so small that we can go a bit faster\n",
    "        train_config.max_iters = 5000\n",
    "        train_config.num_workers = 0\n",
    "        trainer = Trainer(train_config, model, train_dataset)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_score  = evaluate_model_accuracy(model, eval_test_dataset, 100)\n",
    "\n",
    "        h_s.append(test_score)\n",
    "    accuracy.append(h_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38, 0.54, 0.71]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69237/3900511276.py:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + list(layers_unique))\n",
      "/tmp/ipykernel_69237/3900511276.py:19: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Reshape accuracy data for heatmap\n",
    "# accuracy_matrix = np.array([score[2] for score in accuracy]).reshape(len(layers_unique), len(heads_unique))\n",
    "\n",
    "print (accuracy)\n",
    "scores = np.array(accuracy) / 10000\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(scores, cmap='viridis')\n",
    "\n",
    "# Add color bar\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xticklabels([''] + list(layers_unique))\n",
    "ax.set_yticklabels([''])\n",
    "ax.set_xlabel('Layers')\n",
    "# ax.set_ylabel('Heads')\n",
    "\n",
    "# Set title\n",
    "plt.title('Accuracy Heatmap')\n",
    "plt.savefig('../plots/mul_accuracy_heatmap.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
