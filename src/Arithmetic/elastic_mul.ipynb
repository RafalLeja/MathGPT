{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(3407)\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 1, 2, 3, 11, 13, 10, 4, 5, 6, 11, 12, 10, 6, 11, 14, 17]\n",
      "123+456*6=\n"
     ]
    }
   ],
   "source": [
    "StT = {\n",
    "    \"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9,\n",
    "    \"NumBeg\": 10, \"NumEnd\": 11, \"*\": 12, \"+\": 13, \"=\": 14, \"ThinkBeg\": 15, \"ThinkEnd\": 16, \"Eos\": 17\n",
    "}\n",
    "\n",
    "TtS = {v: k for k, v in StT.items()}\n",
    "\n",
    "def tokenize(s):\n",
    "    out = []\n",
    "    num = False\n",
    "    past = \"\"\n",
    "    for c in s:\n",
    "        chars = past + c\n",
    "        if chars in StT:\n",
    "            tok = StT[chars]\n",
    "            if tok < 10:\n",
    "                if not num:\n",
    "                    out.append(StT[\"NumBeg\"])\n",
    "                    num = True\n",
    "                out.append(tok)\n",
    "            else:\n",
    "                if num:\n",
    "                    out.append(StT[\"NumEnd\"])\n",
    "                    num = False\n",
    "                out.append(tok)\n",
    "            past = \"\"\n",
    "        else:\n",
    "            past += c\n",
    "\n",
    "    return out + [StT[\"Eos\"]]\n",
    "\n",
    "def detokenize(toks):\n",
    "    out = []\n",
    "    num = False\n",
    "    for tok in toks:\n",
    "        if tok == 17:\n",
    "            break\n",
    "        \n",
    "        if tok == 10 or tok == 11 or (tok >= 15 and tok <= 17) :\n",
    "            continue\n",
    "        out.append(TtS[tok])\n",
    "\n",
    "    return \"\".join(out)\n",
    "\n",
    "example = \"123+456*6=\"\n",
    "print(tokenize(example))\n",
    "print(detokenize(tokenize(example)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536*62=ThinkBeg500*62+30*62+6*62=31000+1860+372=ThinkEnd33232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def step_mul(length):\n",
    "    a = [random.randint(0,9) for i in range(length)]\n",
    "    b = [random.randint(0,9) for i in range(length)]\n",
    "    # a = [9, 9, 9]\n",
    "    # b = [9, 9, 9]\n",
    "\n",
    "    val_a = int(''.join(str(d) for d in a))\n",
    "    val_b = int(''.join(str(d) for d in b))\n",
    "    if val_a < val_b:\n",
    "        val_a, val_b = val_b, val_a\n",
    "        a, b = b, a\n",
    "    \n",
    "    string = f\"{val_a}*{val_b}=ThinkBeg\"\n",
    "\n",
    "    steps_eq = []\n",
    "    for i in range(length):\n",
    "        a_i = a[i] * 10**(length-i-1)\n",
    "        # a_i = str(a[i]) \n",
    "        string += f\"{a_i}*{val_b}+\"\n",
    "        steps_eq.append(str(a_i*val_b)+\"+\")\n",
    "\n",
    "    string = string[:-1] + \"=\" + \"\".join(steps_eq)[:-1] + \"=\" + \"ThinkEnd\" + str(val_a*val_b)\n",
    "\n",
    "    return string\n",
    "    # print(out)\n",
    "\n",
    "eq = step_mul(3)\n",
    "print(eq)\n",
    "tokenize(eq)\n",
    "len(tokenize(eq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Add problem. E.g. for problem length 3:\n",
    "    12 + 333 = 345\n",
    "    Input: 0 1 2 3 3 3 -> Output: 0 3 4 5\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:  0 1 2 3 3 3 0 3 4\n",
    "    output: I I I I I 0 3 4 5\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 100000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return len(StT)\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return 79\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            rai = tokenize(step_mul(self.length))\n",
    "            h = hash(str(rai[:1+2*(self.length+2)]))\n",
    "            \n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        if len(rai) < self.get_block_size():\n",
    "            rai += [StT[\"Eos\"]] * (self.get_block_size() - len(rai))\n",
    "        \n",
    "        x = torch.tensor(rai[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(rai[1:], dtype=torch.long)\n",
    "        \n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        y[:2*(self.length+2)+1] = -1\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  4,  9,  5, 11, 12, 10,  3,  7,  8, 11, 14, 15, 10,  4,  0,  0, 11,\n",
      "        12, 10,  3,  7,  8, 11, 13, 10,  9,  0, 11, 12, 10,  3,  7,  8, 11, 13,\n",
      "        10,  5, 11, 12, 10,  3,  7,  8, 11, 14, 10,  1,  5,  1,  2,  0,  0, 11,\n",
      "        13, 10,  3,  4,  0,  2,  0, 11, 13, 10,  1,  8,  9,  0, 11, 14, 16, 10,\n",
      "         1,  8,  7,  1,  1,  0])\n",
      "10 -1\n",
      "4 -1\n",
      "9 -1\n",
      "5 -1\n",
      "11 -1\n",
      "12 -1\n",
      "10 -1\n",
      "3 -1\n",
      "7 -1\n",
      "8 -1\n",
      "11 -1\n",
      "14 15\n",
      "15 10\n",
      "10 4\n",
      "4 0\n",
      "0 0\n",
      "0 11\n",
      "11 12\n",
      "12 10\n",
      "10 3\n",
      "3 7\n",
      "7 8\n",
      "8 11\n",
      "11 13\n",
      "13 10\n",
      "10 9\n",
      "9 0\n",
      "0 11\n",
      "11 12\n",
      "12 10\n",
      "10 3\n",
      "3 7\n",
      "7 8\n",
      "8 11\n",
      "11 13\n",
      "13 10\n",
      "10 5\n",
      "5 11\n",
      "11 12\n",
      "12 10\n",
      "10 3\n",
      "3 7\n",
      "7 8\n",
      "8 11\n",
      "11 14\n",
      "14 10\n",
      "10 1\n",
      "1 5\n",
      "5 1\n",
      "1 2\n",
      "2 0\n",
      "0 0\n",
      "0 11\n",
      "11 13\n",
      "13 10\n",
      "10 3\n",
      "3 4\n",
      "4 0\n",
      "0 2\n",
      "2 0\n",
      "0 11\n",
      "11 13\n",
      "13 10\n",
      "10 1\n",
      "1 8\n",
      "8 9\n",
      "9 0\n",
      "0 11\n",
      "11 14\n",
      "14 16\n",
      "16 10\n",
      "10 1\n",
      "1 8\n",
      "8 7\n",
      "7 1\n",
      "1 1\n",
      "1 0\n",
      "0 17\n"
     ]
    }
   ],
   "source": [
    "# print an example instance of the dataset\n",
    "train_dataset = MulDataset('train')\n",
    "test_dataset = MulDataset('test')\n",
    "x, y = train_dataset[0]\n",
    "\n",
    "print (x)\n",
    "for a, b in zip(x,y):\n",
    "    print(int(a),int(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type: None\n",
      "n_layer: 12\n",
      "n_head: 8\n",
      "n_embd: 256\n",
      "vocab_size: None\n",
      "block_size: None\n",
      "embd_pdrop: 0.1\n",
      "resid_pdrop: 0.1\n",
      "attn_pdrop: 0.1\n",
      "\n",
      "number of parameters: 9.50M\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT\n",
    "\n",
    "HEADS = 8\n",
    "LAYERS = 12\n",
    "EMBEDDING_DIM = 256\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = None\n",
    "# model_config.model_type = 'gpt-nano'\n",
    "model_config.n_head = HEADS\n",
    "model_config.n_layer = LAYERS\n",
    "model_config.n_embd = EMBEDDING_DIM\n",
    "print (model_config)\n",
    "\n",
    "model_config.vocab_size = train_dataset.get_vocab_size()\n",
    "model_config.block_size = train_dataset.get_block_size()\n",
    "model = GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make sure the model directory exists\n",
    "if not os.path.exists(f'../weights/elasitc/el_mul_{HEADS}_{LAYERS}'):\n",
    "    os.makedirs(f'../weights/elasitc/el_mul_{HEADS}_{LAYERS}')\n",
    "    model.load_state_dict(torch.load(f'../weights/elastic/el_mul_{HEADS}_{LAYERS}/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 12 256\n"
     ]
    }
   ],
   "source": [
    "print (model_config.n_head, model_config.n_layer, model_config.n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 1e-6 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 5000\n",
    "train_config.num_workers = 0\n",
    "# train_config.batch_size = 32\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 0.04060\n",
      "iter_dt 435.05ms; iter 100: train loss 0.02424\n",
      "iter_dt 430.29ms; iter 200: train loss 0.02249\n",
      "iter_dt 437.78ms; iter 300: train loss 0.02493\n",
      "iter_dt 435.56ms; iter 400: train loss 0.02429\n",
      "iter_dt 430.29ms; iter 500: train loss 0.02646\n",
      "iter_dt 436.54ms; iter 600: train loss 0.02481\n",
      "iter_dt 437.03ms; iter 700: train loss 0.02286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter_dt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39miter_dt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mms; iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39miter_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mset_callback(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_batch_end\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_end_callback)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/minGPT/mingpt/trainer.py:89\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m     data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m     88\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[0;32m---> 89\u001b[0m batch \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     90\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# forward the model\u001b[39;00m\n",
      "File \u001b[0;32m~/minGPT/mingpt/trainer.py:89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     87\u001b[0m     data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m     88\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[0;32m---> 89\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     90\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# forward the model\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's perform some evaluation\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  6,  2,  4, 11, 12, 10,  5,  3,  4, 11, 14])\n",
      "tensor([10,  3,  3,  3,  2,  1,  6, 17])\n",
      "10 10\n",
      "6 3\n",
      "2 3\n",
      "4 3\n",
      "11 2\n",
      "12 1\n",
      "10 6\n",
      "5 17\n"
     ]
    }
   ],
   "source": [
    "class EvalMulDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Add problem. E.g. for problem length 3:\n",
    "    12 + 333 = 345\n",
    "    Input: 0 1 2 3 3 3 -> Output: 0 3 4 5\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:  0 1 2 3 3 3 0 3 4\n",
    "    output: I I I I I 0 3 4 5\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 100000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return len(StT)\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return 79\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            rai = tokenize(step_mul(self.length))\n",
    "            h = hash(str(rai[:1+2*(self.length+2)]))\n",
    "            \n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        x = torch.tensor(rai[:-1], dtype=torch.long)[:rai.index(StT[\"=\"])+1]\n",
    "        y = torch.tensor(rai[1:], dtype=torch.long)[rai.index(StT[\"ThinkEnd\"]):]\n",
    "        \n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        return x, y\n",
    "    \n",
    "eval_train_dataset = EvalMulDataset('train')\n",
    "eval_test_dataset = EvalMulDataset('test')\n",
    "x, y = eval_train_dataset[0]\n",
    "\n",
    "print (x)\n",
    "print (y)\n",
    "for a, b in zip(x,y):\n",
    "    print(int(a),int(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10,  9,  7,  2, 11, 12, 10,  2,  2,  0, 11, 14, 15, 10,  9,  0,  0, 11,\n",
      "         12, 10,  2,  2,  0, 11, 13, 10,  7,  0, 11, 12, 10,  2,  2,  0, 11, 13,\n",
      "         10,  2, 11, 12, 10,  2,  2,  0, 11, 14, 10,  1,  9,  8,  0,  0,  0, 11,\n",
      "         13, 10,  1,  5,  4,  0,  0, 11, 13, 10,  4,  4,  0, 11, 14, 16, 10,  2,\n",
      "          1,  3,  8,  4,  0, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 12, 10,  0]], device='cuda:0')\n",
      "972*220=\n",
      "972*220=900*220+70*220+2*220=198000+15400+440=213840\n",
      "Accuracy: 6/10 = 0.60\n",
      "Accuracy: 11/20 = 0.55\n",
      "Accuracy: 17/30 = 0.57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(detokenize(input_tensor[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(detokenize(out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[0;32m---> 41\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_test_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[66], line 16\u001b[0m, in \u001b[0;36mevaluate_model_accuracy\u001b[0;34m(model, eval_dataset, n)\u001b[0m\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m79\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(detokenize(x[0].cpu().numpy()))\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(detokenize(y[0].cpu().numpy()))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detokenize(y[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/minGPT/mingpt/model.py:293\u001b[0m, in \u001b[0;36mGPT.generate\u001b[0;34m(self, idx, max_new_tokens, temperature, do_sample, top_k)\u001b[0m\n\u001b[1;32m    291\u001b[0m idx_cond \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;28;01mif\u001b[39;00m idx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size \u001b[38;5;28;01melse\u001b[39;00m idx[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size:]\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# forward the model to get the logits for the index in the sequence\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m logits, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# pluck the logits at the final step and scale by desired temperature\u001b[39;00m\n\u001b[1;32m    295\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m/\u001b[39m temperature\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/minGPT/mingpt/model.py:271\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mdrop(tok_emb \u001b[38;5;241m+\u001b[39m pos_emb)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh:\n\u001b[0;32m--> 271\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mln_f(x)\n\u001b[1;32m    273\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/minGPT/mingpt/model.py:92\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     91\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x))\n\u001b[0;32m---> 92\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlpf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/minGPT/mingpt/model.py:88\u001b[0m, in \u001b[0;36mBlock.__init__.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleDict(\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     82\u001b[0m     c_fc    \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mn_embd, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mn_embd),\n\u001b[1;32m     83\u001b[0m     c_proj  \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mn_embd, config\u001b[38;5;241m.\u001b[39mn_embd),\n\u001b[1;32m     84\u001b[0m     act     \u001b[38;5;241m=\u001b[39m NewGELU(),\n\u001b[1;32m     85\u001b[0m     dropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mresid_pdrop),\n\u001b[1;32m     86\u001b[0m ))\n\u001b[1;32m     87\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlpf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: m\u001b[38;5;241m.\u001b[39mdropout(m\u001b[38;5;241m.\u001b[39mc_proj(m\u001b[38;5;241m.\u001b[39mact(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate_model_accuracy(model, eval_dataset, n = 100):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(eval_dataset)):\n",
    "            x, y = eval_dataset[i]\n",
    "            x = x.unsqueeze(0).to(device)\n",
    "            y = y.unsqueeze(0).to(device)\n",
    "\n",
    "            output = model.generate(x, 79, do_sample=False)\n",
    "            # print(detokenize(x[0].cpu().numpy()))\n",
    "            # print(detokenize(y[0].cpu().numpy()))\n",
    "            y = int(detokenize(y[0].cpu().numpy()))\n",
    "            predicted = int(detokenize(output[0].cpu().numpy()).split(\"=\")[-1])\n",
    "            # print(predicted)\n",
    "\n",
    "            # Compare predicted and actual values\n",
    "            correct += 1 if y == predicted else 0\n",
    "            total += 1\n",
    "\n",
    "            if total % 10 == 0:\n",
    "                print(f\"Accuracy: {correct}/{total} = {correct/total:.2f}\")\n",
    "\n",
    "            if total >= n:\n",
    "                break\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "input_tensor = eval_test_dataset[0][0].unsqueeze(0).to(device)\n",
    "out = model.generate(input_tensor, 120, do_sample=False)\n",
    "print(out)\n",
    "print(detokenize(input_tensor[0].cpu().numpy()))\n",
    "print(detokenize(out[0].cpu().numpy()))\n",
    "accuracy = evaluate_model_accuracy(model, eval_test_dataset)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../weights/elastic/el_mul_{HEADS}_{LAYERS}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 4.76M\n",
      "running on device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69237/3834584001.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'../weights/elastic/el_mul_{heads}_{layers}.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4/10 = 0.40\n",
      "Accuracy: 5/20 = 0.25\n",
      "Accuracy: 11/30 = 0.37\n",
      "Accuracy: 14/40 = 0.35\n",
      "Accuracy: 18/50 = 0.36\n",
      "Accuracy: 21/60 = 0.35\n",
      "Accuracy: 23/70 = 0.33\n",
      "Accuracy: 29/80 = 0.36\n",
      "Accuracy: 33/90 = 0.37\n",
      "Accuracy: 38/100 = 0.38\n",
      "number of parameters: 6.34M\n",
      "running on device cuda\n",
      "Accuracy: 6/10 = 0.60\n",
      "Accuracy: 15/20 = 0.75\n",
      "Accuracy: 20/30 = 0.67\n",
      "Accuracy: 25/40 = 0.62\n",
      "Accuracy: 30/50 = 0.60\n",
      "Accuracy: 33/60 = 0.55\n",
      "Accuracy: 39/70 = 0.56\n",
      "Accuracy: 43/80 = 0.54\n",
      "Accuracy: 48/90 = 0.53\n",
      "Accuracy: 54/100 = 0.54\n",
      "number of parameters: 9.50M\n",
      "running on device cuda\n",
      "Accuracy: 5/10 = 0.50\n",
      "Accuracy: 13/20 = 0.65\n",
      "Accuracy: 22/30 = 0.73\n",
      "Accuracy: 29/40 = 0.72\n",
      "Accuracy: 35/50 = 0.70\n",
      "Accuracy: 42/60 = 0.70\n",
      "Accuracy: 50/70 = 0.71\n",
      "Accuracy: 56/80 = 0.70\n",
      "Accuracy: 64/90 = 0.71\n",
      "Accuracy: 71/100 = 0.71\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "\n",
    "heads_unique = [8]\n",
    "layers_unique = [6, 8, 12]\n",
    "\n",
    "for heads in heads_unique:\n",
    "    h_s = []\n",
    "    for layers in layers_unique:\n",
    "        model_config = GPT.get_default_config()\n",
    "        model_config.model_type = None\n",
    "        model_config.n_head = heads\n",
    "        model_config.n_layer = layers\n",
    "        model_config.n_embd = 256\n",
    "        model_config.vocab_size = train_dataset.get_vocab_size()\n",
    "        model_config.block_size = train_dataset.get_block_size()\n",
    "        # print (model_config)\n",
    "        model = GPT(model_config)\n",
    "\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.load_state_dict(torch.load(f'../weights/elastic/el_mul_{heads}_{layers}.pth', map_location=device))\n",
    "\n",
    "        train_config = Trainer.get_default_config()\n",
    "        train_config.learning_rate = 1e-4 # the model we're using is so small that we can go a bit faster\n",
    "        train_config.max_iters = 5000\n",
    "        train_config.num_workers = 0\n",
    "        trainer = Trainer(train_config, model, train_dataset)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_score  = evaluate_model_accuracy(model, eval_test_dataset, 100)\n",
    "\n",
    "        h_s.append(test_score)\n",
    "    accuracy.append(h_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38, 0.54, 0.71]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69237/2271232381.py:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + list(layers_unique))\n",
      "/tmp/ipykernel_69237/2271232381.py:19: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Reshape accuracy data for heatmap\n",
    "# accuracy_matrix = np.array([score[2] for score in accuracy]).reshape(len(layers_unique), len(heads_unique))\n",
    "\n",
    "print (accuracy)\n",
    "scores = np.array(accuracy)\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(scores, cmap='viridis')\n",
    "\n",
    "# Add color bar\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xticklabels([''] + list(layers_unique))\n",
    "ax.set_yticklabels([''])\n",
    "ax.set_xlabel('Layers')\n",
    "# ax.set_ylabel('Heads')\n",
    "\n",
    "# Set title\n",
    "plt.title('Accuracy Heatmap')\n",
    "plt.savefig('../plots/mul_accuracy_heatmap.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
