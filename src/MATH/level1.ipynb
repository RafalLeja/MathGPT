{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafal/.local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/rafal/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "from bpe import Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"mathurinache/math-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "problems = {\"problem\": [], \"level\": [], \"type\": [], \"solution\": []}\n",
    "\n",
    "with os.scandir(path + \"/MATH/train/\") as types:\n",
    "    for type in types:\n",
    "        if type.is_dir():\n",
    "            with os.scandir(type) as entries:\n",
    "                for entry in entries:\n",
    "                    if entry.is_file():\n",
    "                        # print(entry.path)\n",
    "                        with open(entry.path) as f:\n",
    "                            data = json.load(f)\n",
    "                            for key in data:\n",
    "                                problems[key].append(data[key])\n",
    "\n",
    "all_levels = pd.DataFrame.from_dict(problems, orient='columns')\n",
    "\n",
    "BLOCK_SIZE = max(all_levels[\"problem\"].apply(len) + all_levels[\"solution\"].apply(len))\n",
    "BLOCK_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479 / 6375\n",
      "85 / 1125\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(all_levels, test_size=0.15, random_state=42, stratify=all_levels['level'])\n",
    "\n",
    "print(len(train[train['level'] == \"Level 1\"]), '/', len(train))\n",
    "print(len(test[test['level'] == \"Level 1\"]), '/', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 229, 56, 60, 61, 282, 69, 60, 61, 225, 230, 86, 66, 60, 17, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "corpus_arr = train[\"problem\"].tolist() + train[\"solution\"].tolist() + test[\"problem\"].tolist() + test[\"solution\"].tolist()\n",
    "\n",
    "corpus = \" \".join(corpus_arr)\n",
    "\n",
    "encoder = Encoder(500, pct_bpe=0.88)\n",
    "encoder.fit(corpus.split(\"\\n\"))\n",
    "\n",
    "example = \"Add two numbers 3 and 4\"\n",
    "print(next(encoder.transform([example])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.16M\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt-nano'\n",
    "model_config.vocab_size = encoder.vocab_size\n",
    "model_config.block_size = 1024\n",
    "model = GPT(model_config)\n",
    "\n",
    "BLOCK_SIZE = 1024\n",
    "\n",
    "print(encoder.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 61, 222,  88,  ...,   0,   0,   0]),\n",
       " tensor([-1, -1, -1,  ...,  0,  0,  0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mingpt.bpe import BPETokenizer\n",
    "\n",
    "tokenizer = BPETokenizer()\n",
    "\n",
    "class MathDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        return BLOCK_SIZE\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        problem = self.data.iloc[idx]['problem']\n",
    "        solution = self.data.iloc[idx]['solution']\n",
    "        input = next(encoder.transform([problem + \" \" + solution]))\n",
    "        # print(input)\n",
    "        x = torch.Tensor(input[:-1]).long()\n",
    "        y = torch.Tensor(input[1:]).long()\n",
    "        \n",
    "        if len(x) > BLOCK_SIZE:\n",
    "            return self.__getitem__(idx + 1)\n",
    "        \n",
    "        if len(x) < BLOCK_SIZE:\n",
    "            x = torch.cat((x, torch.zeros(BLOCK_SIZE - len(x)).long()))\n",
    "            y = torch.cat((y, torch.zeros(BLOCK_SIZE - len(y)).long()))\n",
    "\n",
    "        \n",
    "\n",
    "        y[:len(problem)] = -1\n",
    "        # print(x, y)\n",
    "        return x, y\n",
    "        \n",
    "    \n",
    "train_dataset = MathDataset(train)\n",
    "test_dataset = MathDataset(test)\n",
    "\n",
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 1e-5 # many possible options, see the file\n",
    "train_config.max_iters = 1000\n",
    "train_config.batch_size = 32\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 0.81358\n",
      "iter_dt 633.39ms; iter 10: train loss 1.17957\n",
      "iter_dt 632.46ms; iter 20: train loss 1.09480\n",
      "iter_dt 632.47ms; iter 30: train loss 0.92683\n",
      "iter_dt 630.57ms; iter 40: train loss 1.05396\n",
      "iter_dt 631.93ms; iter 50: train loss 0.87323\n",
      "iter_dt 629.09ms; iter 60: train loss 0.75698\n",
      "iter_dt 634.79ms; iter 70: train loss 0.84890\n",
      "iter_dt 630.92ms; iter 80: train loss 0.87772\n",
      "iter_dt 633.35ms; iter 90: train loss 0.98032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter_dt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39miter_dt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mms; iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39miter_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mset_callback(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_batch_end\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_end_callback)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/minGPT/mingpt/trainer.py:89\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m     data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m     88\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[0;32m---> 89\u001b[0m batch \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     90\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# forward the model\u001b[39;00m\n",
      "File \u001b[0;32m~/minGPT/mingpt/trainer.py:89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     87\u001b[0m     data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m     88\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[0;32m---> 89\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     90\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# forward the model\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 10 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(500, 48)\n",
       "    (wpe): Embedding(1024, 48)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-2): 3 x Block(\n",
       "        (ln_1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=48, out_features=144, bias=True)\n",
       "          (c_proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=48, out_features=192, bias=True)\n",
       "          (c_proj): Linear(in_features=192, out_features=48, bias=True)\n",
       "          (act): NewGELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=48, out_features=500, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  7,  61, 125,  ...,   0,   0,   0])\n",
      "the line joining $( 3 , 2 )$ and $( 6 , 0 )$ divides the square shown into two parts . what fraction of the area of the square is above this line ? express your answer as a common fraction . [ asy ] draw ((- 2 , 0 )--( 7 , 0 ), linewidth ( 1 ), arrows ); draw (( 0 ,- 1 )--( 0 , 4 ), linewidth ( 1 ), arrows ); draw (( 1 ,. 25 )--( 1 ,-. 25 ), linewidth ( 1 )); draw (( 2 ,. 25 )--( 2 ,-. 25 ), linewidth ( 1 )); draw (( 3 ,. 25 )--( 3 ,-. 25 ), linewidth ( 1 )); draw (( 4 ,. 25 )--( 4 ,-. 25 ), linewidth ( 1 )); draw (( 5 ,. 25 )--( 5 ,-. 25 ), linewidth ( 1 )); draw (( 6 ,. 25 )--( 6 ,-. 25 ), linewidth ( 1 )); draw ((. 25 , 1 )--(-. 25 , 1 ), linewidth ( 1 )); draw ((. 25 , 2 )--(-. 25 , 2 ), linewidth ( 1 )); draw ((. 25 , 3 )--(-. 25 , 3 ), linewidth ( 1 )); draw (( 3 , 0 )--( 6 , 0 )--( 6 , 3 )--( 3 , 3 )--( 3 , 0 )-- cycle , linewidth ( 2 )); label (\"$ y $\",( 0 , 4 ), n ); label (\"$ x $\",( 7 , 0 ), e ); label (\"$( 3 , 0 )$\",( 3 , 0 ), s ); label (\"$( 6 , 3 )$\",( 6 , 3 ), n ); [/ asy ] the triangle below the line has height 2 , and base 3 , making for a total area of 3 , which is $\\ frac { 1 }{ 3 }$ of the total area , meaning that $\\ frac { 2 }{ 3 }$ of the area is above the line . you can also do this by visually dividing the square into 3 equal - area horizontal rectangles , noticing that the triangle covers half the area of the bottom two , thereby leaving $\\ boxed {\\ frac { 2 }{ 3 }}$ of the square above the line __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk __unk\n"
     ]
    }
   ],
   "source": [
    "input = test_dataset.__getitem__(0)\n",
    "print(input[0])\n",
    "output = model.generate(input[0].unsqueeze(0).cuda(), 100)\n",
    "print(next(encoder.inverse_transform(output.cpu().numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../weights/math_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
